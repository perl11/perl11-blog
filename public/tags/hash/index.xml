<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hash on perl11 blog</title>
    <link>http://perl11.org/blog/tags/hash.xml</link>
    <description>Recent content in Hash on perl11 blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Â© 2016 Copyright Reini Urban</copyright>
    <atom:link href="http://perl11.org/blog/tags/hash.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>strict hashpairs</title>
      <link>http://perl11.org/blog/strict-hashpairs.html</link>
      <pubDate>Tue, 16 May 2017 00:00:00 +0000</pubDate>
      
      <guid>http://perl11.org/blog/strict-hashpairs.html</guid>
      <description>

&lt;h1 id=&#34;perl5-optionally-warns-on-odd-hash-elements&#34;&gt;perl5 optionally warns on odd hash elements&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;my %h = (0,1,2);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;is legal code in perl5. The second pair is constructed with the undef value.
With &lt;code&gt;use warnings &#39;misc&#39;&lt;/code&gt; it will warn at least.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;use warnings;
my %h = (0,1,2);
=&amp;gt; Odd number of elements in hash assignment (WARNING only)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;perl6-throws-on-odd-hash-elements&#34;&gt;perl6 throws on odd hash elements&lt;/h1&gt;

&lt;p&gt;perl6 is sane and strict by default.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;my %h = (0..2);
=&amp;gt; Odd number of elements found where hash initializer expected:
Found 3 (implicit) elements:
Last element seen: 2
  in block &amp;lt;unit&amp;gt; at &amp;lt;unknown file&amp;gt; line 1
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;cperl-5-27-throws-with-use-strict&#34;&gt;cperl 5.27 throws with use strict&lt;/h1&gt;

&lt;p&gt;Since cperl 5.27.0 use strict added two new keys: &lt;strong&gt;&amp;lsquo;hashpairs&amp;rsquo;&lt;/strong&gt; and
&amp;lsquo;names&amp;rsquo;.&lt;/p&gt;

&lt;p&gt;strict hashpairs ensure that no hashes can get created from lists or arrays with odd elements.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;use strict;
my %h = (0,1,2);
=&amp;gt; Only pairs in hash assignment allowed while &amp;quot;strict hashpairs&amp;quot;, got 3 elements
Execution of -e aborted due to compilation errors
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With constant arrays or lists this is even a compile-time error, as seen above.&lt;/p&gt;

&lt;p&gt;With map it is even more strict. With map only a missing or a single
pair is allowed to construct a hash, not multiple pairs.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;use strict;
my %h = map {$_=&amp;gt;1, $_+1} (0..2);
=&amp;gt; Only pair in map hash assignment allowed while &amp;quot;strict hashpairs&amp;quot;, got 3 elements
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This was legal in perl5 and is now a run-time error. Net::DNS did it
to construct two pairs in one loop.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;use strict;
my %h = map {$_} @array;
=&amp;gt; Only pair in map hash assignment allowed while &amp;quot;strict hashpairs&amp;quot;, got 1 elements
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Typical oddities, which are now forbidden:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;%h = map { $ =&amp;gt; (0,1) } (0..3);
=&amp;gt; 1=&amp;gt;3, 2=&amp;gt;0, 0=&amp;gt;1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Only 3 keys, not 4. Because &lt;code&gt;@h=map{$=&amp;gt;(0,1)}(0..3);print join&amp;quot; &amp;quot;,@h&#39;&lt;/code&gt;
=&amp;gt; &lt;code&gt;0 0 1 1 0 1 2 0 1 3 0 1&lt;/code&gt; and the duplicate keys collapse.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;%h = map { $_ } (0..3);
=&amp;gt; 2=&amp;gt;3, 0=&amp;gt;1 (2 keys, of course)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;more-warnings&#34;&gt;More warnings&lt;/h1&gt;

&lt;p&gt;cperl 5.27 added detection for more &amp;ldquo;Odd elements&amp;rdquo; warnings, esp.
when a map assigned to a hash produces no pairs.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;no strict;
use warnings;
%h = map { $_ } (0..1);
# =&amp;gt; Odd number of map elements in hash assignment
%h = map { $_ =&amp;gt; (0,1) } (0..1);
# =&amp;gt; Odd number of map elements in hash assignment
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The warning is only produced once for each map, not for every map iteration.&lt;/p&gt;

&lt;h1 id=&#34;cpan-impact&#34;&gt;CPAN Impact&lt;/h1&gt;

&lt;p&gt;One might think changing the strictness of the language might break a lot of modules.
Thanksfully most module authors already use sane coding principles, only a few
produce multiple pairs per map to a hash.&lt;/p&gt;

&lt;p&gt;All of them have been fixed in my distroprefs patches, and some also upstream.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Net-NDS: &lt;a href=&#34;https://rt.cpan.org/Ticket/Display.html?id=121680&#34;&gt;https://rt.cpan.org/Ticket/Display.html?id=121680&lt;/a&gt; &lt;a href=&#34;https://github.com/rurban/distroprefs/commit/63cd16b8359d1ccd062f0c4b913fa77b4b8681ff&#34;&gt;rurban/distroprefs@63cd16b&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Moose: &lt;a href=&#34;https://github.com/rurban/distroprefs/commit/f929f794fc64b5fef3b29c81f5b313c28f60da92&#34;&gt;rurban/distroprefs@f929f79&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;DBI: &lt;a href=&#34;https://github.com/rurban/distroprefs/commit/2f0c82d7e938e8d10420c3d76eab235fbb229fff&#34;&gt;rurban/distroprefs@2f0c82d&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Class::Tiny &lt;a href=&#34;https://github.com/rurban/distroprefs/commit/02054335a9c30aa3d5d7abfe7ca6002d5ccd4033&#34;&gt;rurban/distroprefs@0205433&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;MooseX::Types &lt;a href=&#34;https://github.com/rurban/distroprefs/commit/e1e3fc0fc6f03a6dcc6afdf9afd4ac85abd6076a&#34;&gt;rurban/distroprefs@e1e3fc0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Encode &lt;a href=&#34;https://github.com/dankogai/p5-encode/pull/100&#34;&gt;dankogai/p5-encode#100&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Only one module at all used a double pair in a map, Net::DNS. This was easily fixed.
The other modules use &lt;code&gt;%opts = @_;&lt;/code&gt; to assign a hash from the pairwise arguments of a
subroutine call. Perfectly fine usage.&lt;/p&gt;

&lt;p&gt;It get&amp;rsquo;s crazy with something like&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;my %p = map { %{$_} } @_;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;in &lt;code&gt;Moose/Util/TypeConstraints.pm&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Or&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;my %attrs = map { %{ Class::MOP::Class-&amp;gt;initialize($_)-&amp;gt;_attribute_map } }
            reverse $self-&amp;gt;linearized_isa;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;in &lt;code&gt;Class/MOP/Class.pm&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;my %defaults = map { ref $_ eq &#39;HASH&#39; ? %$_ : ( $_ =&amp;gt; undef ) } @spec;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;in &lt;code&gt;Class/Tiny.pm&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;my %order = map {
            my $order = $_;
            map { ( $_ =&amp;gt; $order ) } @{ $dbh-&amp;gt;{sql_init_order}{$order} };
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;in DBI. Here you also see the manual prevention of the problem described
below, protecting the iteration key from the global iterator in nested
map loops.&lt;/p&gt;

&lt;p&gt;These cases just deserve a &lt;code&gt;no strict &amp;quot;hashpairs&amp;quot;&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&#34;sideeffects-and-wrong-order-of-evaluation-in-map&#34;&gt;Sideeffects and wrong order of evaluation in map&lt;/h1&gt;

&lt;p&gt;And now look at these oddities, detected by Patrick Cronin and rafl for their
new &lt;a href=&#34;https://github.com/PatrickCronin/Map-Functional/&#34;&gt;Map::Functional&lt;/a&gt;
module.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sub x{$_,&amp;quot;ouch&amp;quot;}; %h = map { $_ =&amp;gt; x } (0..3);
=&amp;gt; %h =&amp;gt; 3=&amp;gt;ouch, ouch=&amp;gt;3, 1=&amp;gt;ouch, 2=&amp;gt;2, 0=&amp;gt;0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5 not 4 keys. Still the normal list comprehension problem..
But what if the value changes the key?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sub x{$_ = &amp;quot;ouch&amp;quot;}; %h = map { $_ =&amp;gt; x } (0..3);
=&amp;gt; %h =&amp;gt; ouch=&amp;gt;ouch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A sideffect in the value evaluation changed the key, because the &lt;code&gt;$_&lt;/code&gt;
inside the x subroutine is the same as the global &lt;code&gt;$_&lt;/code&gt; loop iterator
inside map.  They experience problems with the global topic trampled
over inside a loop by various other ops, just as &lt;code&gt;while (&amp;lt;&amp;gt;){}&lt;/code&gt; called from
the value, which changed the key.&lt;/p&gt;

&lt;p&gt;Too bad &lt;a href=&#34;http://blogs.perl.org/users/rurban/2016/04/the-removal-of-the-lexical-topic-feature-in-524.html&#34;&gt;perl5 removed the lexical &lt;code&gt;$_&lt;/code&gt; topic&lt;/a&gt;. This
would at least have saved the loop iterator.&lt;/p&gt;

&lt;p&gt;But it is worse than that. It is even broken without a lexical &lt;code&gt;$_&lt;/code&gt;,
and without a function.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;%h = map { $_ =&amp;gt; ($_ = &amp;quot;ouch&amp;quot;) } (0..3);
=&amp;gt; %h =&amp;gt; ouch=&amp;gt;ouch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All the values inside the map are computed at once, hence the first
&lt;code&gt;$_&lt;/code&gt; is changed also, and the list produced by the map block is
consumed later, when the block is done.  In a proper language with
proper of left to right evaluation order the key would be consumed
first, and then the value.&lt;/p&gt;

&lt;p&gt;The underlying design problem is that the map lambda has no formal argument
list, where you could enforce that order. &lt;code&gt;map sub(a,b){ a =&amp;gt; b } (0..3)&lt;/code&gt;
perl5 just uses a block body with a silent &lt;code&gt;($_)&lt;/code&gt; lambda
signature and the return value(s) just spill over to the stack.&lt;/p&gt;

&lt;p&gt;But it is still solvable by detecting lists inside map blocks and
consume them one by one.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;map { $_ =&amp;gt; ($_ = &amp;quot;ouch&amp;quot;) } (0..3);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;is roughly compiled as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mapstart { stmt, stmt } mapwhile rv2av const(AV)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I might change it to:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mapstart { stmt; mapwhile; stmt } mapwhile rv2av const(AV)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The embedded mapwhile op would consume the first element, push it into
the stack and continue. This would make hash assignments via map much safer.&lt;/p&gt;

&lt;h1 id=&#34;strict-names&#34;&gt;strict names&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;strict &amp;lsquo;names&amp;rsquo;&lt;/strong&gt; is not yet enabled. It will check for valid
identifiers being created from strings under no strict &amp;lsquo;refs&amp;rsquo;. Which
helps in &lt;a href=&#34;unicode-identifiers.html&#34;&gt;fighting invalid identifiers&lt;/a&gt;
being created, which cannot be handled by the rest of perl, and
esp. since 5.16 with additional embedded NUL.  cperl 5.26 made
embedded NUL&amp;rsquo;s and invalid unicode
identifiers &lt;a href=&#34;https://github.com/perl11/cperl/issues/233&#34;&gt;illegal&lt;/a&gt;,
and &lt;a href=&#34;https://github.com/perl11/cperl/issues/228&#34;&gt;normalizes unicode identifiers&lt;/a&gt;. But
there&amp;rsquo;s still room left to create invalid and potentially harmful
unicode names. Some cases are only warned against.  strict names will
ensure no illegal name will get created.&lt;/p&gt;

&lt;p&gt;And it clashes with a reserved VMS hint. Means on VMS strict names will be a no-op.&lt;/p&gt;

&lt;h1 id=&#34;comments-on-r-cperl-https-www-reddit-com-r-cperl-comments-6bgya8-strict-hashpairs&#34;&gt;Comments on &lt;a href=&#34;https://www.reddit.com/r/cperl/comments/6bgya8/strict_hashpairs/&#34;&gt;/r/cperl&lt;/a&gt;&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>cperl hash tables</title>
      <link>http://perl11.org/blog/cperl-hash-tables.html</link>
      <pubDate>Sat, 04 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>http://perl11.org/blog/cperl-hash-tables.html</guid>
      <description>

&lt;h1 id=&#34;the-old-perl5-hash-table-uses&#34;&gt;The old perl5 hash table uses&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;linked lists for its collisions, with slow out-of-cache pointer
chasing and data overhead.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;unsorted flags at the end, while some flags are needed for compare.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;has questionable security measures to slow down all cases. seed ok,
randomize iter maybe, but randomize the collisions and slow hash
funcs is stupid. The security should be fixed with proper collision
iteration, not by pseudo-security theatre upfront.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;no collision search abstraction. The internal implementation quirks
leaked into core and even external modules.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;four different HE types. Only one is needed.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;inefficient combination of action flags. many magic hash key lookups
involve internally 3-4 hash lookups.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;was seriously broken 4 times so far.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;in-order-to-clean-up-the-mess-i-did-the-following&#34;&gt;In order to clean up the mess, I did the following&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Added multiple new hash functions, run statistics and evaluated them.
See &lt;a href=&#34;https://github.com/rurban/perl-hash-stats&#34;&gt;perl-hash-stats&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Took over maintainance of the general hash function test suite
&lt;a href=&#34;https://github.com/rurban/smhasher#smhasher&#34;&gt;smhasher&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Attempt to fix the wrong wikipedia entry about hash tables. It
prominently claims that perl5 hash tables are highly optimized, when
in fact they are highly deoptimized, and are in fact the worst and
slowest hash table implementation in existance.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Posted the results to p5p, which was ignored. A few sentences they
said made it clear, that they had no idea what they were
doing. E.g. they made fun of Donald Knuth, and of course of me
&lt;em&gt;(besides calling me an asshole once again)&lt;/em&gt;. Hinting that they
maybe should consult an independent expert sitting in the same
office didn&amp;rsquo;t help. Revising their broken implementation of hash
tables four times so far doesn&amp;rsquo;t improve trust into their abilities.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Started implementing perfect hashes, because they were needed to
speed up all the readonly hashes in core (Config, warnings, unicode
tables).  Found some interesting new results, esp. how to speed
up memcmp by &lt;a href=&#34;http://blogs.perl.org/users/rurban/2014/08/perfect-hashes-and-faster-than-memcmp.html&#34;&gt;50% - 2000%&lt;/a&gt;
with a constant string.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Studied hash function and hash table security, and detected a lot of
theatre and wrong practices in most dynamic languages, but
interestingly not in the more technical-orientated important public
services, usually maintained by a single person. Apparently
community driven development in large teams is the worst,
contradicting &lt;a href=&#34;http://www.catb.org/esr/writings/cathedral-bazaar/&#34;&gt;&amp;ldquo;The Cathedral and the Bazaar&amp;rdquo;&lt;/a&gt;. I&amp;rsquo;ll have to seperate that into a new blog post. There are
many more tellsigns of community-based development agony.
Wrote brute-force and solver-based attacks. (&lt;em&gt;No, I&amp;rsquo;m not gonna publish
these&lt;/em&gt;).  So far I could only convince google to revise their
documentation.  Added hashflood testcases to cperl to test detecting
such attacks.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;cperl-hash-tables-use&#34;&gt;cperl hash tables use&lt;/h1&gt;

&lt;p&gt;â a &lt;strong&gt;fast and short hash function&lt;/strong&gt; &lt;a href=&#34;https://github.com/rurban/smhasher#smhasher&#34;&gt;FNV1A&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;â proper DoS and DDoS &lt;strong&gt;security&lt;/strong&gt; by detecting attacks, logging and
  mitigating it. Not using the slowest of all usable hash function
  SipHash, as this doesn&amp;rsquo;t really help against attacks.&lt;/p&gt;

&lt;p&gt;â &lt;code&gt;PERTURB_KEYS_TOP&lt;/code&gt; &lt;strong&gt;move-to-front&lt;/strong&gt; with a linked list is the only
  sane strategy for simple chained bucket lists with many reads.&lt;/p&gt;

&lt;p&gt;â &lt;code&gt;HV_FILL_RATE&lt;/code&gt;: try lower fill rates than 100%.
  100% is pretty insane, esp. with our bad hash funcs. Make it fast with builtin_ctz.
  &lt;a href=&#34;https://github.com/rurban/perl-hash-stats#fill-rates&#34;&gt;&lt;img src=&#34;https://github.com/rurban/perl-hash-stats/raw/master/hash-fillrate-def-FNV1A.png&#34; alt=&#34;FNV1A fill rates&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;â use &lt;code&gt;builtin_ctz&lt;/code&gt; for faster division in &lt;code&gt;DO_HSPLIT&lt;/code&gt;.
  Allow &lt;code&gt;-DHV_FILL_RATE=90&lt;/code&gt; definition. (Tested to be the best with &lt;code&gt;FNV1A&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;â extract uncommon magical code in hot code to an extra static
  function to help keep the icache smaller. only in rare cases this
  branch is taken. (i.e filling ENV at startup). Measured 2-15% faster
  with normal scripts, not using tied hashes.&lt;/p&gt;

&lt;p&gt;â fixed &lt;code&gt;-DNODEFAULT_SHAREKEYS&lt;/code&gt;, preventing every single hash lookup
  to be done twice.  First in strtab, then in the real hash.&lt;/p&gt;

&lt;p&gt;â &lt;strong&gt;pre-extend&lt;/strong&gt; the hash size to the size of the resulting hashes in many cases
  to avoid initialization splits:
  internal stashes of some known packages, internal hashes of some known size,
  fix the hash assign operator to that in user-code.&lt;/p&gt;

&lt;p&gt;and several other minor optimizations. Typically 20% faster than in perl5.&lt;/p&gt;

&lt;h1 id=&#34;cperl-is-working-on-these-improvements&#34;&gt;cperl is working on these improvements:&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;abstraction of the abstract &lt;strong&gt;HE_EACH&lt;/strong&gt; collision iterator in the
&lt;a href=&#34;https://github.com/perl11/cperl/commits/feature/gh24-base-hash&#34;&gt;feature/gh24-base-hash&lt;/a&gt; branch &lt;em&gt;(stable)&lt;/em&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;array_he: &lt;strong&gt;abstract AHE&lt;/strong&gt;, inline parts of the HE into the
array. array_he vs ll_he. (linked list, see also the he-array
branch). array_he (&lt;code&gt;HvARRAY = AHE[]&lt;/code&gt;) can contain
&lt;code&gt;{ hent_he, hent_hash }&lt;/code&gt;. This way the hash catches 99% of all comparisons
already, and we don&amp;rsquo;t have to chase the external hek ptr, when the
hash check fails. Every HE entry is then be 2 words (128), instead
of one word (64), called AHE. The linked list still contains the old
&lt;code&gt;HE*&lt;/code&gt;, with &lt;code&gt;{ hent_next, hent_hek, hent_val }&lt;/code&gt;. This is implemented and
works fine in the
&lt;a href=&#34;https://github.com/perl11/cperl/commits/feature/gh24-hash-loop&#34;&gt;featurex/gh24-hash-loop&lt;/a&gt; branch &lt;em&gt;(stable)&lt;/em&gt;, and on top of that the &lt;a href=&#34;https://github.com/perl11/cperl/commits/feature/gh24-array_he&#34;&gt;featurex/gh24-array_he&lt;/a&gt; branch,
which is the base to most other hash tables below.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;HE_ARRAY: According to
&lt;a href=&#34;http://goanna.cs.rmit.edu.au/~jz/fulltext/spire05.pdf&#34;&gt;http://goanna.cs.rmit.edu.au/~jz/fulltext/spire05.pdf&lt;/a&gt; the best for
chained hashing is currently a &lt;strong&gt;cache-friendly array of buckets&lt;/strong&gt;,
instead of a linked list. cache-friendly continuous buffer of HE&amp;rsquo;s
w/ inlined HEK (char&lt;em&gt;) + SV&lt;/em&gt; val, but no hash, no next ptr. Also for
shared he&amp;rsquo;s: PL_strtab.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/perl11/cperl/issues/102&#34;&gt;small hash type&lt;/a&gt;:
linear search in embedded array up to 7 keys. ruby, v8 and several
others measured 3-5 to be a big win, esp. for their object fields,
but we don&amp;rsquo;t even have that yet. avoid the hash init, calc and search
overhead, esp. with our overly slow hash tables.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;hash-sortbuckets: a sorted static list of collisions (up to 8, maybe
start with 3, then 8) as in the Knuth &lt;strong&gt;&amp;ldquo;ordered hash table&amp;rdquo;&lt;/strong&gt;. We will not
use that.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;khash&lt;/strong&gt;: use open addressing as everyone else. faster, less space. But
khash needs a few fixes. And we can not use that, as perl5 is not properly
abstracted to be able to use external hash tables.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;one-word-AHE&lt;/strong&gt;: As possible improvement on that on 64bit use 48bits
for the HE ptr, and 16bits of the hash to be compared first. See
&lt;a href=&#34;https://www.semanticscholar.org/paper/Fast-Dynamically-Sized-Concurrent-Hash-Table-Barnat-Rockai/ab7dd007587f411cf99bfe056639e055eff22e0c/pdf&#34;&gt;https://www.semanticscholar.org/paper/Fast-Dynamically-Sized-Concurrent-Hash-Table-Barnat-Rockai/ab7dd007587f411cf99bfe056639e055eff22e0c/pdf&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;use &lt;strong&gt;robin-hood&lt;/strong&gt; as this is currently the best worse-case strategy
(being super defensive, but not so stupid to use SipHash, which adds
no benefit). With better native threading support (shared hashes)
eventually use &lt;strong&gt;leapfrog&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;compact ordered hash&lt;/strong&gt;. use an array of short indices into a compacted
array of hash/key/val entries as in PyPy and now python: &amp;ldquo;compact
ordered dict&amp;rdquo;. This saves a lot of space and only add&amp;rsquo;s one indirect
lookup into cache-friendly array. See methane/cpython#1
&lt;a href=&#34;https://mail.python.org/pipermail/python-dev/2016-September/146327.html&#34;&gt;https://mail.python.org/pipermail/python-dev/2016-September/146327.html&lt;/a&gt;
This also iterates over the hash in insertion order, which
effectively hides any attempt to get the seed over the
iterators. For attacks you need to get collision and robin-hood
reordering timings.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;get rid of &lt;strong&gt;HEK_WASUTF8&lt;/strong&gt;. &amp;ldquo;There shall be only one state, not
two&amp;rdquo;. Rather fix the encoding bug (CPAN) instead.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;p5p-plans&#34;&gt;p5p plans&lt;/h1&gt;

&lt;p&gt;p5p announced that it is working on switching to an abstract vtable
for hash tables, which is similar to their idea to run-time switch
hash functions truly horrendous.  They say it is needed to abstract
readonly (i.e. perfect hashes), and maybe tied and restricted
hashes.&lt;/p&gt;

&lt;p&gt;The cost of this would be another indirection in every hash
table call, and I don&amp;rsquo;t see any benefit.&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t see a cleanup of the monstrous implementation and different
types and attempts to actually improve any of the problematic issues.
As usual with p5p it will make the situation even worse, not better.&lt;/p&gt;

&lt;h1 id=&#34;conflicts&#34;&gt;Conflicts&lt;/h1&gt;

&lt;p&gt;Having worked with &lt;code&gt;PERTURB_KEYS_TOP&lt;/code&gt; move-to-front in cperl for a few
years now, there&amp;rsquo;s only one broken module Text::CVS_XS, which assumes
in one of its testcases for parse without headers that the ordering of
keys is stable when the size did not change. The fix is in my
&lt;a href=&#34;https://github.com/rurban/distroprefs/blob/master/sources/authors/id/R/RU/RURBAN/patches/Text-CSV_XS-cperl.patch&#34;&gt;distroprefs&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;comments-on-r-cperl-https-www-reddit-com-r-cperl-comments-5xofay-cperl-hash-tables&#34;&gt;Comments on &lt;a href=&#34;https://www.reddit.com/r/cperl/comments/5xofay/cperl_hash_tables/&#34;&gt;/r/cperl&lt;/a&gt;&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>The dangerous SipHash myth</title>
      <link>http://perl11.org/blog/seed.html</link>
      <pubDate>Sat, 26 Nov 2016 12:35:00 +0200</pubDate>
      
      <guid>http://perl11.org/blog/seed.html</guid>
      <description>&lt;p&gt;SipHash claims that its &amp;ldquo;cryptographically strong pseudo random
function&amp;rdquo; properties protects against hash table DoS flood attacks.
This is wrong, because for a successful attack against a SipHash hash
table with chained linked lists or linear probing it is enough to get
the secret random seed, and then brute force create collisions, which
is doable in &amp;lt;1s for 16k keys, 2m for 16k keys, and from 32k to 268M
keys in 4 minutes. For any hash function, SipHash, AES or even SHA256.
Which is far from being secure. Declaring a hash function for a hash
table secure is wrong and pure security theatre, which unfortunately
a lot of people started to believe in.&lt;/p&gt;

&lt;p&gt;Normally you can prepare collisions offline, but as you see you can
even create them online as soon as you know the seed.  Inserting 64k
keys needs 32 seconds vs 0.01 seconds on e.g. PHP, from constant to
quadratic, with an amplification factor of 200.
&lt;a href=&#34;https://events.ccc.de/congress/2011/Fahrplan/events/4680.en.html&#34;&gt;https://events.ccc.de/congress/2011/Fahrplan/events/4680.en.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So the only protection is the secrecy of the random seed, which has
nothing to do with any properties of SipHash per se. A hash
function can never protect a hash table from hash flood attacks on
hash tables with simple lists on collisions. SipHash properties are
that is not reversible, the seed is mixed in the box and not only
at the beginning, so it&amp;rsquo;s is hard to get the seed from the hash
function itself. But there&amp;rsquo;s no need for it, as it is trivial to
get the seed via other means. The collisions are prone to timing
attacks independent on the hash function, usually the hash
iterator exposes the inner ordering and in most cases the random
seed is exposable via traditional memory exposure. If the seed is
hash table specific or global, i.e. process or thread specific.&lt;/p&gt;

&lt;p&gt;E.g. in debian perl you get the seed at process startup via&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ PERL_HASH_SEED_DEBUG=1 /usr/bin/perl -e0
=&amp;gt; HASH_FUNCTION = ONE_AT_A_TIME_HARD HASH_SEED = 0xd12d459fc36db4cf PERTURB_KEYS = 1 (RANDOM)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to stderr.&lt;/p&gt;

&lt;p&gt;On centos7:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ PERL_HASH_SEED_DEBUG=1 /usr/bin/perl -e0
=&amp;gt; HASH_SEED = 10452142639498245987
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Older centos 5 and 6 has an unpatched perl hash table function which
is vulnerable to much simplier DoS attacks, which is e.g. used on the
redhat openshift public cloud.&lt;/p&gt;

&lt;p&gt;For a running perl process the seed is at a known fixed offset.  Which
is easily readable via some kind of poke function via the unpack &amp;ldquo;P&amp;rdquo;
builtin op. See Devel::PeekPoke.  Similar for all other dynamic
languages exposing the value of any pointer. Which is esp. problematic
for languages who trusted the false claims of the SipHash authors,
that using this secure hash function it makes it safe against such DoS
attacks. Which are most prominently ruby, python, rust, haskell and
others.  Perl5 at least changed the order of the iterator, cperl
counts the collisions and adds a sleep on attacks, PHP limits the size
of external keys to be passed to the hash table so only JSON or other
formats are easily DoS-able. But more serious applications such as the
linux kernel, glibc, cache or DNS servers use better hash table
collisions schemes than unsafe chaining or linear probing.&lt;/p&gt;

&lt;p&gt;Vulnerable are all implementors of hash tables who believed the false
claims of the SipHash authors: ruby, python, rust, haskell, OpenBSD
and some more.  But also others who don&amp;rsquo;t use a proper hash table
collision resolution scheme or don&amp;rsquo;t protect their seed or easily
expose the seed, such as perl5 and many more.  rust currently
e.g. believes that SipHash makes it secure even if a trivial attack
was just found against it, and changing the seed at table resize will
help. It only helps a bit.  The seed is still exposable.  With an
amplification factor of 200 with a table size large enough there&amp;rsquo;s
enough attack surface to render a service useless.
Reseeding on resize will lead to an amplification factor of 6.&lt;/p&gt;

&lt;p&gt;Links:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/google/highwayhash/issues/28&#34;&gt;google/highwayshash False security claims&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/rurban/smhasher/#security&#34;&gt;SMHasher on Security&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/rurban/perl-hash-stats&#34;&gt;perl hash stats&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>